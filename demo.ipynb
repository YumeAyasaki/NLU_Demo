{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from utils.metric import roc_auc\n",
    "from utils.model import define_rnn_model, define_cnn_model, define_lstm_model, define_gru_model, define_bi_model, define_cnn_rnn_model, define_BERT_model\n",
    "from utils.encode import fast_encode\n",
    "from utils.tokenizer import BERT_tokenizer\n",
    "\n",
    "if not tf.__version__.startswith('2'):\n",
    "    raise ValueError('This code requires TensorFlow V2.x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "o_train = pd.read_csv('Data/jigsaw-toxic-comment-train.csv')\n",
    "\n",
    "# Pre processing\n",
    "o_train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True) # Drop other columns\n",
    "\n",
    "# Get input\n",
    "# type_input = widgets.Dropdown(\n",
    "#     options=['Phần trăm', 'Số lượng'],\n",
    "#     value='Số lượng',\n",
    "#     description='Dữ liệu vào',\n",
    "#     disabled=False,\n",
    "# )\n",
    "# value_input = widgets.IntSlider(\n",
    "#     value=20000,\n",
    "#     min=0,\n",
    "#     max=o_train.shape[0],\n",
    "#     step=1000,\n",
    "#     description='Số lượng',\n",
    "#     readout=True\n",
    "# )\n",
    "\n",
    "# def update_value_input(*args):\n",
    "#     if type_input.value == 'Số lượng':\n",
    "#         value_input.value=50000\n",
    "#         value_input.max=o_train.shape[0]\n",
    "#         value_input.step=1000\n",
    "#         value_input.description='Số lượng'\n",
    "#     else:\n",
    "#         value_input.value=50\n",
    "#         value_input.max=100\n",
    "#         value_input.step=1\n",
    "#         value_input.description='Phần trăm'\n",
    "# type_input.observe(update_value_input, 'value')\n",
    "\n",
    "# display(type_input)\n",
    "# display(value_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_array = ['cnn', 'rnn', 'lstm', 'gru', 'bi_directional', 'cnn + rnn', 'bert']\n",
    "\n",
    "# model_input = widgets.Dropdown(\n",
    "#     options=model_array,\n",
    "#     value='rnn',\n",
    "#     description='Loại mô hình',\n",
    "#     disabled=False,\n",
    "# )\n",
    "\n",
    "# display(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_model = 'bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Embedding\n",
    "# embeddings_index = {}\n",
    "# f = open('glove.840B.300d.txt','r',encoding='utf-8')\n",
    "# for line in tqdm(f):\n",
    "#     values = line.split(' ')\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray([float(val) for val in values[1:]])\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if type_input.value == 'Số lượng':\n",
    "#     train = o_train.loc[:value_input.value,:]\n",
    "# else:\n",
    "#     train = o_train.loc[:value_input.value * o_train.shape[0] / 100,:]\n",
    "train = o_train.loc[:50000,:]\n",
    "max_test = train['comment_text'].apply(lambda x:len(str(x).split())).max() # Max test's length\n",
    "\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, \n",
    "                                                  stratify=train.toxic.values, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = keras.preprocessing.text.Tokenizer(num_words=None)\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "#zero pad the sequences\n",
    "xtrain_pad = keras.preprocessing.sequence.pad_sequences(xtrain_seq, maxlen=max_test)\n",
    "xvalid_pad = keras.preprocessing.sequence.pad_sequences(xvalid_seq, maxlen=max_test)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programming\\NLU\\.conda\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_word_ids (InputLayer)  [(None, 1403)]           0         \n",
      "                                                                 \n",
      " tf_distil_bert_model (TFDis  TFBaseModelOutput(last_h  65190912 \n",
      " tilBertModel)               idden_state=(None, 1403,            \n",
      "                              768),                              \n",
      "                              hidden_states=None, att            \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 768)              0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,191,681\n",
      "Trainable params: 65,191,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "max_vocab = len(word_index) + 1\n",
    "model_type_array = {\n",
    "    # 'cnn': define_cnn_model(max_vocab, max_test),\n",
    "    # 'rnn': define_rnn_model(max_vocab, max_test), \n",
    "    # 'lstm': define_lstm_model(max_vocab, max_test), \n",
    "    # 'gru': define_gru_model(max_vocab, max_test),\n",
    "    # 'bi_directional': define_bi_model(max_vocab, max_test),\n",
    "    # 'cnn + rnn': define_cnn_rnn_model(max_vocab, max_test),\n",
    "    'bert': define_BERT_model(max_test),\n",
    "}\n",
    "model = model_type_array[name_of_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:08<00:00, 19.53it/s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/tf_distil_bert_model/distilbert/transformer/layer_._0/attention/MatMul' defined at (most recent call last):\n    File \"e:\\Programming\\NLU\\.conda\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"e:\\Programming\\NLU\\.conda\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_14396\\1486136080.py\", line 20, in <module>\n      history = model.fit(train_dataset, steps_per_epoch=x_train.shape[0] // 16, validation_data=valid_dataset, epochs=2)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 611, in run_call_with_unpacked_inputs\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 612, in call\n      outputs = self.distilbert(\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 611, in run_call_with_unpacked_inputs\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 465, in call\n      tfmr_output = self.transformer(\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 368, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 372, in call\n      layer_outputs = layer_module(hidden_state, attn_mask, head_mask[i], output_attentions, training=training)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 303, in call\n      sa_output = self.attention(x, x, x, attn_mask, head_mask, output_attentions, training=training)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 199, in call\n      scores = tf.matmul(q, k, transpose_b=True)  # (bs, n_heads, q_length, k_length)\nNode: 'model/tf_distil_bert_model/distilbert/transformer/layer_._0/attention/MatMul'\nOOM when allocating tensor with shape[16,12,1403,1403] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf_distil_bert_model/distilbert/transformer/layer_._0/attention/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_13176]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m      5\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      6\u001b[0m         tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;241m.\u001b[39mfrom_tensor_slices((x_train, ytrain))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     13\u001b[0m     valid_dataset \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     14\u001b[0m         tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;241m.\u001b[39mfrom_tensor_slices((x_valid, yvalid))\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;241m.\u001b[39mcache()\n\u001b[0;32m     18\u001b[0m     )\n\u001b[1;32m---> 20\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name_of_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     22\u001b[0m     history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit([xtrain_pad, xtrain_pad, xtrain_pad], ytrain, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32me:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32me:\\Programming\\NLU\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/tf_distil_bert_model/distilbert/transformer/layer_._0/attention/MatMul' defined at (most recent call last):\n    File \"e:\\Programming\\NLU\\.conda\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"e:\\Programming\\NLU\\.conda\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_14396\\1486136080.py\", line 20, in <module>\n      history = model.fit(train_dataset, steps_per_epoch=x_train.shape[0] // 16, validation_data=valid_dataset, epochs=2)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 611, in run_call_with_unpacked_inputs\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 612, in call\n      outputs = self.distilbert(\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 611, in run_call_with_unpacked_inputs\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 465, in call\n      tfmr_output = self.transformer(\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 368, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 372, in call\n      layer_outputs = layer_module(hidden_state, attn_mask, head_mask[i], output_attentions, training=training)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 303, in call\n      sa_output = self.attention(x, x, x, attn_mask, head_mask, output_attentions, training=training)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"e:\\Programming\\NLU\\.conda\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 199, in call\n      scores = tf.matmul(q, k, transpose_b=True)  # (bs, n_heads, q_length, k_length)\nNode: 'model/tf_distil_bert_model/distilbert/transformer/layer_._0/attention/MatMul'\nOOM when allocating tensor with shape[16,12,1403,1403] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf_distil_bert_model/distilbert/transformer/layer_._0/attention/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_13176]"
     ]
    }
   ],
   "source": [
    "if name_of_model == 'bert':\n",
    "    # Do different things for BERT\n",
    "    x_train = fast_encode(xtrain, BERT_tokenizer(), maxlen=max_test)\n",
    "    x_valid = fast_encode(xvalid, BERT_tokenizer(), maxlen=max_test)\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_train, ytrain))\n",
    "        .repeat()\n",
    "        .shuffle(2048)\n",
    "        .batch(16)\n",
    "    )\n",
    "\n",
    "    valid_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_valid, yvalid))\n",
    "        .batch(16)\n",
    "        .cache()\n",
    "    )\n",
    "    \n",
    "    history = model.fit(train_dataset, steps_per_epoch=x_train.shape[0] // 16, validation_data=valid_dataset, epochs=2)\n",
    "elif name_of_model == 'cnn':\n",
    "    history = model.fit([xtrain_pad, xtrain_pad, xtrain_pad], ytrain, epochs=10)\n",
    "    model.save('cnn.h5')\n",
    "    scores = model.predict([xvalid_pad, xvalid_pad, xvalid_pad])\n",
    "    print(\"Auc: %.2f%%\" % (roc_auc(scores, yvalid)))\n",
    "else:\n",
    "    history = model.fit(xtrain_pad, ytrain, epochs=10)\n",
    "    model.save(name_of_model.value + '.h5')\n",
    "    scores = model.predict(xvalid_pad)\n",
    "    print(\"Auc: %.2f%%\" % (roc_auc(scores, yvalid)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
